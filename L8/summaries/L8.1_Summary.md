Author: Samuel Solorzano Ramirez (A00354798)

Course: Software Engineering

Smart Bear Software: Best Practices for Peer Code Review
=====

1- Review fewer than 200 - 400 lines of code at a time
-----

Reviewing 200 - 400 LOC spread over no more than 60-90 minutes we should get 70-90% yield: in other words if 10 defects existed, we'd find 7-9 of them.

2- Aim for an inspection rate of less tah 300-500 LOC/hour
-----

Faster is not better. The research showed that an optimal result is in between 300-500LOC/hour, In rates above 1000 LOC/hour, we can probably conclude that the reviewer is actually not looking at code.

3- Take enough time for a proper, slow review, but no more than 60-90 minutes
-----

We should not review for too long in one sitting, after 60 minutes the reviewer is wear out and stops findings defects. Never the less, we should spend at least 5 minutes reviewing code.

4- Author should annotate source code before the review begins
-----

Annotations guide the reviewer through the changes, showing which files to look at first and defending the reason and methods behind each code modification. These notes are not comments in the code, but rather comments given to other reviewers.

The theory was that because the author has to re-think and explain the changes during the annotation process, the author will himself uncover many of the defects before the review even begins, thus making the review itself more efficient. In these cases the review process should yield a lower defect density,

5- Establish quantifiable goals for code review and capture metrics so you can improve your processes.
-----

Decide in advance on the goals of the code review process and how you will measure its effectiveness.  Collect your metrics and tweak your processes to see how changes affect your results. WIth the information I'll know exactly what works best for the team.

6- Checklist substantially improve results for both authors and reviewers
-----

Omissions are the hardest defects to find – after all, it’s hard to review something that’s not there. A checklist is the single best way to combat the problem, as it reminds the reviewer or author to take the time to look for something that might be missing.

7- Verify that defects are actually fixed
-----

If you’re going to go to the trouble of finding the bugs, make sure you’ve fixed them all!

8- Managers must foster a good code review culture in which finding defects is viewed positively
-----

Managers must promote the viewpoint that defects are positive. Every defect found and fixed in peer review is a defect a customer never saw, another problem QA didn’t have to spend time tracking down.

Teams should maintain the attitude that finding defects means the author and reviewer have successfully worked as a team to jointly improve the product.

9- Beware the "Big Brother" Effect
-----

“Big Brother is watching you.” Metrics should never be used to single out developers, particularly in front of their peers. This practice can seriously damage morale.

10- The Ego effect: Do at least some code review, even if you don't have time to review at all
-----

The “Ego Effect” drives developers to write better code because they know that others will be looking at their code and their metrics. And no one wants to be known as the guy who makes all those junior-level mistakes. The Ego Effect drives developers to review their own work carefully before passing it on to others.

11- Lightweight-style code reviews are efficient, practical, and effective at finding bugs.
-----

The most effective reviews are conducted using a collaborative software tool to facilitate the review.
